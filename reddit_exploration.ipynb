{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import CSV's into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1363, 24)\n",
      "Index(['approved_by', 'archived', 'author', 'author_flair_text',\n",
      "       'comment_limit', 'created', 'distinguished', 'downs', 'gilded', 'id',\n",
      "       'is_video', 'likes', 'name', 'num_comments', 'num_crossposts',\n",
      "       'over_18', 'pinned', 'quarantine', 'score', 'selftext', 'send_replies',\n",
      "       'subreddit_id', 'title', 'ups'],\n",
      "      dtype='object')\n",
      "(6671, 18)\n",
      "Index(['_submission', 'approved_by', 'archived', 'author', 'author_flair_text',\n",
      "       'body', 'comment_id', 'created', 'distinguished', 'downs', 'gilded',\n",
      "       'link_id', 'name', 'parent_id', 'score', 'send_replies', 'subreddit_id',\n",
      "       'ups'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_submissions = pd.read_csv(\"reddit_submissions_2018-04-25_2034.csv\",\n",
    "skipinitialspace=True,\n",
    "header = 0,\n",
    "sep = ',',\n",
    "index_col=0,\n",
    "encoding='latin1').fillna('')\n",
    "print(df_submissions.shape)\n",
    "print(df_submissions.columns)\n",
    "\n",
    "df_comments = pd.read_csv(\"reddit_comments_2018-04-25_2034.csv\",\n",
    "skipinitialspace=True,\n",
    "header = 0,\n",
    "sep = ',',\n",
    "index_col=0,\n",
    "encoding='latin1').fillna('')\n",
    "print(df_comments.shape)\n",
    "print(df_comments.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_comments = df_comments.rename(columns={'_submission':'id',\n",
    "                                         'body':'selftext'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8034, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['approved_by', 'archived', 'author', 'author_flair_text', 'comment_id',\n",
       "       'comment_limit', 'created', 'distinguished', 'downs', 'gilded', 'id',\n",
       "       'is_video', 'likes', 'link_id', 'name', 'num_comments',\n",
       "       'num_crossposts', 'over_18', 'parent_id', 'pinned', 'quarantine',\n",
       "       'score', 'selftext', 'send_replies', 'subreddit_id', 'title', 'ups',\n",
       "       'comment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = df_submissions.append(df_comments)\n",
    "df_all['comment'] = np.where(df_all['comment_id'].isnull(),0,1)\n",
    "print(df_all.shape)\n",
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***print submission***\n",
      "Head 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: comment, dtype: int64\n",
      "***print comments***\n",
      "Bottom 0    1\n",
      "0    1\n",
      "0    1\n",
      "0    1\n",
      "Name: comment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('***print submission***')\n",
    "print('Head {}'.format(df_all['comment'][0:5]))\n",
    "print('***print comments***')\n",
    "print('Bottom {}'.format(df_all['comment'][-5:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count # of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014\n",
      "1024\n",
      "8029\n"
     ]
    }
   ],
   "source": [
    "print(df_all['id'].nunique())\n",
    "print(df_all['author'].nunique())\n",
    "print(df_all['selftext'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Search in the text by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- submission_id\n",
    "- comment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528    my wife is pregnant and will soon be going on mat leave. last year she used income averaging so she could spend some more time with our son and will fibish paying it off just before maf leave starts.\\r\\r\\n\\r\\r\\ndoes anyone have any experience going on mat leave following income averaging? when u submitted your best weeks pay for ei did you provide your pay before income averaging was taken off or did you provide your pay without income averaging?\\r\\r\\n\\r\\r\\nfor example say she made 2000 gros...\n",
      "590    hi friends, like most of you here i am experiencing a lot of pay issues. i√¢?ve decided to go back to when we were all moved over to phoenix (may 2016), and calculate my pay and deductions (i.e. gross vs net), and things are going sideways very quickly. \\r\\r\\n\\r\\r\\ncit, cpp, and ei that were deducted from my gross pay are not the same as the calculations i am making based on the rates posted on the cra website for the 2016 tax year. for example, on one of my pays it appears as though my cit d...\n",
      "743                                                                                                                                                                                                                                                                                     i worked with cra for three tax seasons, and i'm starting with the ei call center. i'm assuming it's very similar work, but i'm just interested in what to expect overall, and relative to working on the cra general phonelines. \n",
      "881                                                                                                                                                                                                                                                                                                              on my paystubs my only tax deductions are ei and cpp and those only end up deducting less then 10% of my gross income. i make over 55k, shouldn't there be more deductions in provincial and federal tax?\n",
      "0      my wife is pregnant and will soon be going on mat leave. last year she used income averaging so she could spend some more time with our son and will fibish paying it off just before maf leave starts.\\r\\n\\r\\ndoes anyone have any experience going on mat leave following income averaging? when u submitted your best weeks pay for ei did you provide your pay before income averaging was taken off or did you provide your pay without income averaging?\\r\\n\\r\\nfor example say she made 2000 gross (per 2...\n",
      "Name: selftext, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pattern = 'security'\n",
    "df_all['selftext'] = df_all['selftext'].str.lower()\n",
    "df_pattern = df_all[df_all['selftext'].str.contains(pattern.lower())]\n",
    "print(df_pattern['selftext'][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_subm_comment(df):\n",
    "    pattern_comment_id = []\n",
    "    pattern_subm_id = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row['comment']==0:\n",
    "            pattern_comment_id.append(df_pattern['comment_id'])\n",
    "        if row['comment']==1:\n",
    "            pattern_subm_id.append(df_pattern['comment_id'])\n",
    "    return pattern_comment_id, pattern_subm_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Submissions or comments with the \"security\": 270 \n",
      "Number of Submissions with the \"security\": 193 \n",
      "Number of comments with the \"security\": 77 \n"
     ]
    }
   ],
   "source": [
    "pattern_comment_id, pattern_subm_id = find_subm_comment(df_pattern)\n",
    "\n",
    "print('Number of Submissions or comments with the \"{}\": {} '.format(pattern,len(df_pattern)))\n",
    "print('Number of Submissions with the \"{}\": {} '.format(pattern,len(pattern_subm_id)))\n",
    "print('Number of comments with the \"{}\": {} '.format(pattern,len(pattern_comment_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extract Key Words of submission or comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Very important', 'Somewhat important'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "important_names = pd.read_csv(\"Important_Names.csv\",\n",
    "    skipinitialspace=True,\n",
    "    header = 0,\n",
    "    sep = ',',\n",
    "    encoding='latin1').fillna('')\n",
    "\n",
    "print(important_names.columns)\n",
    "important_names = list(important_names['Very important'])\n",
    "\n",
    "while '' in important_names:\n",
    "    important_names.remove('')\n",
    "\n",
    "program_names = pd.read_csv(\"program_names.csv\",\n",
    "    skipinitialspace=True,\n",
    "    header = 0,\n",
    "    sep = ',',\n",
    "    encoding='latin1').fillna('')\n",
    "\n",
    "program_names = list(program_names['names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programs Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ale/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "list_occurences = []\n",
    "for word in program_names:\n",
    "    pattern = word\n",
    "    df_pattern = df_all[df_all['selftext'].str.contains(pattern.lower())]\n",
    "    pattern_comment_id, pattern_subm_id = find_subm_comment(df_pattern)\n",
    "    list_occurences.append([len(pattern_comment_id), len(pattern_subm_id)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passport --> [0, 11]\n",
      "other government department programs --> [0, 0]\n",
      "old age security --> [0, 2]\n",
      "canada pension plan --> [0, 0]\n",
      "the canada pension plan disability --> [0, 0]\n",
      "canada disability savings program --> [0, 0]\n",
      "national child benefit --> [0, 0]\n",
      "labour relations --> [2, 20]\n",
      "canada student loans and grants --> [0, 0]\n",
      "canada education savings program --> [0, 0]\n",
      "early learning and child care --> [0, 0]\n",
      "indigenous early learning and child care --> [0, 0]\n",
      "canadian poverty reduction --> [0, 0]\n",
      "social innovation and social finance --> [0, 0]\n",
      "government of canada telephone general enquiries services --> [0, 0]\n",
      "government of canada internet presence --> [0, 0]\n",
      "in-person points of service --> [0, 0]\n",
      "employment insurance --> [0, 4]\n",
      "labour market agreements for persons with disabilities --> [0, 0]\n",
      "opportunities fund for persons with disabilities --> [0, 0]\n",
      "youth employment strategy --> [0, 0]\n",
      "enabling fund for official language minority communities --> [0, 0]\n",
      "aboriginal skills and employment training strategy --> [0, 0]\n",
      "skills and partnership fund --> [0, 0]\n",
      "job bank and labour market information --> [0, 0]\n",
      "sectoral initiatives program --> [0, 0]\n",
      "the office of literacy and essential skills --> [0, 0]\n",
      "skilled trades and apprenticeship (red seal program) --> [0, 0]\n",
      "foreign credential recognition program --> [0, 0]\n",
      "temporary foreign worker --> [0, 0]\n",
      "oas --> [4, 19]\n",
      "cpp --> [13, 20]\n",
      "gis --> [22, 64]\n",
      "tfw --> [0, 1]\n",
      "ei --> [501, 1769]\n",
      "esdc --> [8, 33]\n",
      "hrsdc --> [0, 1]\n",
      "job bank  --> [0, 0]\n",
      "service canada --> [9, 18]\n",
      "employment and social development canada --> [8, 6]\n",
      "human resources and skills development canada --> [0, 0]\n",
      "canada summer jobs  --> [0, 0]\n"
     ]
    }
   ],
   "source": [
    "dict_program_name = dict(zip(program_names,list_occurences))\n",
    "for key, values in dict_program_name.items():\n",
    "    print('{} --> {}'.format(key, values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "['Jos√©e Duplessis', 'Emilie Gauduchon', 'Mathieu Filion', 'Matthew Mitschke', 'Matt Pascuzzo', 'Carlene Variyan', 'Jude Welch', 'Annabelle Archambault', 'Jane Almeida', 'Adam Vaughan', 'Rodger Cuzner', 'St√©phane Lauzon', 'Peter Schiefke', 'Jean-Yves Duclos', 'Duclos', 'Patty Hajdu', 'Hajdu', 'Kirsty Duncan', 'Duncan', 'Kent Hehr', 'Hehr', 'Christopher Simard', 'Olivier Bouffard', 'Amelie Maisonneuve', 'Joshua Bueckert', 'Carla Qualtrough', 'Qualtrough']\n"
     ]
    }
   ],
   "source": [
    "print(type(important_names[0]))\n",
    "print(important_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_occurences = []\n",
    "for word in important_names:\n",
    "    pattern = word\n",
    "    df_pattern = df_all[df_all['selftext'].str.contains(pattern.lower())]\n",
    "    pattern_comment_id, pattern_subm_id = find_subm_comment(df_pattern)\n",
    "    list_occurences.append([len(pattern_comment_id), len(pattern_subm_id)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jos√©e Duplessis --> [0, 0]\n",
      "Emilie Gauduchon --> [0, 0]\n",
      "Mathieu Filion --> [0, 0]\n",
      "Matthew Mitschke --> [0, 0]\n",
      "Matt Pascuzzo --> [0, 0]\n",
      "Carlene Variyan --> [0, 0]\n",
      "Jude Welch --> [0, 0]\n",
      "Annabelle Archambault --> [0, 0]\n",
      "Jane Almeida --> [0, 0]\n",
      "Adam Vaughan --> [0, 0]\n",
      "Rodger Cuzner --> [0, 0]\n",
      "St√©phane Lauzon --> [0, 0]\n",
      "Peter Schiefke --> [0, 0]\n",
      "Jean-Yves Duclos --> [0, 0]\n",
      "Duclos --> [0, 0]\n",
      "Patty Hajdu --> [0, 0]\n",
      "Hajdu --> [0, 0]\n",
      "Kirsty Duncan --> [0, 0]\n",
      "Duncan --> [0, 0]\n",
      "Kent Hehr --> [0, 0]\n",
      "Hehr --> [0, 0]\n",
      "Christopher Simard --> [0, 0]\n",
      "Olivier Bouffard --> [0, 0]\n",
      "Amelie Maisonneuve --> [0, 0]\n",
      "Joshua Bueckert --> [0, 0]\n",
      "Carla Qualtrough --> [0, 6]\n",
      "Qualtrough --> [0, 20]\n"
     ]
    }
   ],
   "source": [
    "dict_important_names = dict(zip(important_names,list_occurences))\n",
    "for key, values in dict_important_names.items():\n",
    "    print('{} --> {}'.format(key, values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keywords ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alex_\\Anaconda3\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.summarization import keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering - Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
